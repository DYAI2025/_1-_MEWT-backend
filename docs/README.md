Marker System ‚Äì README
Grundprinzipien: Markerklassen & Ebenen
Das System analysiert Kommunikation, indem es bedeutungsvolle Muster (sog. Marker) in vier hierarchischen Klassen/Abstraktionsebenen erfasst. Jeder Marker-Typ hat eine klar definierte Rolle und Interaktionslogik.

1. Atomic Marker (A_)
Funktion:
Atomic Marker sind die elementarsten Einheiten im System. Sie erkennen einfache, klar abgrenzbare Muster direkt im Text, z.‚ÄØB. bestimmte Emojis, Schl√ºsselw√∂rter, Satzmuster oder regul√§re Ausdr√ºcke.

Beispiel:

A_FAREWELL_EMOJI.yaml erkennt Emojis wie üëã oder üíî am Satzende.

A_APPEAL_TO_AUTHORITY.yaml erkennt Formulierungen wie ‚ÄûLaut Experten‚Ä¶‚Äú oder ‚ÄûStudien zeigen‚Ä¶‚Äú.

Technik:

Definiert in YAML, Pflichtfelder: id, level=1, name, description, pattern[], examples[].

Wird von Detect-Regeln (regex etc.) direkt getriggert.

Atomic Marker sind immer ‚ÄûSingular‚Äú ‚Äì sie bilden die Basis f√ºr alle komplexeren Marker.

2. Semantic Marker (S_)
Funktion:
Semantic Marker gruppieren mehrere Atomic Marker oder einfache Regeln zu einem bedeutungsvolleren Muster. Sie beschreiben z.‚ÄØB. Kommunikations- oder Beziehungsmuster, die durch eine Kombination einfacher Elemente entstehen.

Beispiel:

S_EMO_VOLATILE_WINDOW.yaml aggregiert mehrere emotionale Schwankungen (A_ Marker) √ºber ein Nachrichtenfenster.

S_ABSAGE_INDIR.yaml erkennt indirekte Absagen, wenn bestimmte Formulierungen wiederholt auftreten.

Technik:

YAML, Pflichtfelder wie bei A_, aber zus√§tzlich: composed_of[] (enth√§lt IDs von A_ oder anderen S_), activation_logic.

Aktivierungslogik legt fest, wie die Atomic Marker zum Ausl√∂sen kombiniert werden (z.‚ÄØB. Schwellenwert, Zeitfenster, Reihenfolge).

Semantic Marker sind die ‚ÄûRegel-Ebene‚Äú ‚Äì sie verbinden Basismuster zu logischen Bedeutungsgruppen.

3. Cluster Marker (C_)
Funktion:
Cluster Marker b√ºndeln mehrere Semantic Marker (und ggf. Atomic Marker) zu √ºbergeordneten Beziehungsmustern oder Kommunikationsclustern. Sie bilden die Br√ºcke zwischen einzelnen Signalgruppen und komplexen Dynamiken, etwa Eskalationsmustern oder Ritualverlusten.

Beispiel:

C_EMOTIONAL_WITHDRAWAL.yaml triggert, wenn Marker f√ºr R√ºckzug, Affektverflachung und reduzierte Resonanz gemeinsam auftreten.

C_SEEKING_AFFECTION_RITUALIZED.yaml erkennt Cluster von Bindungssuche √ºber verschiedene Ausdrucksformen.

Technik:

YAML, Pflichtfelder wie bei S_, mit level=3, composed_of[], optional trigger_threshold.

Cluster Marker definieren, wie viele und welche S_/A_ Marker (innerhalb eines Zeitraums) gemeinsam vorliegen m√ºssen, damit ein √ºbergeordnetes Muster ausgel√∂st wird.

Sie erm√∂glichen die Erkennung von ‚ÄûDriftzonen‚Äú, z.‚ÄØB. Beziehungskrisen, Eskalation oder Ann√§herung.

4. Meta Marker (MM_)
Funktion:
Meta Marker sind die h√∂chste Abstraktionsebene. Sie detektieren komplexe, oft systemische Kommunikations- oder Beziehungsmuster, die aus mehreren Cluster-Mustern zusammengesetzt sind. Meta Marker spiegeln z.‚ÄØB. die Dynamik einer kompletten Eskalationsphase, einer Patchwork-Kommunikation oder tiefliegende Manipulationsstrategien wider.

Beispiel:

MM_PARADOXAL_CONNECTION_TEST.yaml erkennt, wenn verschiedene Cluster-Marker f√ºr N√§he und R√ºckzug in paradoxen Konstellationen gemeinsam ausgel√∂st werden.

MM_META_DRIFT.yaml erkennt l√§ngere Phasen semantischer Drift, in denen verschiedene Cluster (Distanz, Maskierung, Ironie) systematisch die Beziehungsebene ver√§ndern.

Technik:

YAML, Pflichtfelder: id, level=4, required_clusters[], window.

required_clusters[] definiert, welche C_ (und evtl. S_) Marker gemeinsam in einem Zeitraum vorliegen m√ºssen.

Meta Marker agieren auf ‚ÄûMakro‚Äú-Ebene: Sie interpretieren die Marker- und Cluster-Historie, fassen sie zu Diagnosen, Alerts oder Relationstrends zusammen.

Zusammenspiel der Marker-Klassen
Atomic Marker liefern rohe Signale.

Semantic Marker gruppieren und interpretieren diese Signale logisch.

Cluster Marker identifizieren verdichtete Muster, die f√ºr Beziehungen oder Systeme relevant sind.

Meta Marker ordnen ganze Phasen, Musterketten oder systemische Drifts ein.

Ablauf:

Detect-Runner erkennt im Text primitive Muster ‚Üí feuert A_ Marker.

Semantic Marker beobachten, ob relevante Kombinationen von A_ vorliegen ‚Üí feuern S_ Marker.

Cluster Marker aggregieren √ºber Nachrichtenfenster ‚Üí feuern C_ Marker, sobald bestimmte Schwellen √ºberschritten sind.

Meta Marker beobachten die Verteilung und Historie von C_/S_ Marker ‚Üí feuern MM_ Marker f√ºr umfassende Dynamik- oder Risiko-Alerts.

Vorteil:
Das System bleibt granular, nachvollziehbar und adaptiv ‚Äì neue Marker lassen sich einfach erg√§nzen, bestehende Regelwerke pr√§zisieren.

Schema-Profil (Schemata) ‚Äì SCH_
Funktion:
Ein Schema-Profil (Plural: Schemata, Prefix: SCH_) legt fest, wie Marker gewichtet und interpretiert werden. Es steuert, wie wichtig einzelne Marker oder Gruppen in einer Analyse sind, wie Scores berechnet werden, welche Fenster und Aggregationslogiken gelten und welche Drift- oder Schwellenwerte eingesetzt werden.

Beispiel:

SCH_BEZIEHUNG.json gibt hoher Emotionalit√§tsdynamik (z.‚ÄØB. C_EMOTIONAL_WITHDRAWAL) einen h√∂heren Score als Smalltalk-Marker.

SCH_FRAUD.json gewichtet Indizien f√ºr T√§uschung und Manipulation besonders hoch.

Technik:

Format: JSON, im Ordner /schemata/

Pflichtfelder:

id (Schema-Name)

weights (Mapping: Marker-IDs ‚Üí Scorefaktor)

window (Nachrichtenfenster zur Aggregation, z.‚ÄØB. 10, 20)

decay (optional: Score-Abschw√§chung √ºber Zeit/Fenster)

Erweiterungen: Schwellenwerte f√ºr Cluster/Meta-Trigger, Score-Fusion-Strategie, aktive Driftachsen.

Zusammenspiel:
Schemata werden vom Master-Schema aktiviert oder gewechselt. Sie bestimmen, wie Detektionen in Bewertungen, Alerts oder Reports umgesetzt werden. Mehrere Schemata k√∂nnen parallel (mit Gewichtung) oder sequentiell (per Phase) eingesetzt werden.

Master-Schema (MASTER_SCH_)
Funktion:
Das Master-Schema (Prefix: MASTER_SCH_) ist die zentrale Steuerinstanz f√ºr den Schema-Einsatz. Es bestimmt, welche Schemata zu einem Zeitpunkt aktiv sind, wie ihre Scores fusioniert werden und mit welcher Priorit√§t sie in die Analyse einflie√üen.

Beispiel:

MASTER_SCH_CORE.json legt fest: ‚ÄûBeziehungsschema‚Äú z√§hlt mit Gewicht 0.7, ‚ÄûFraud‚Äú mit 0.9, ‚ÄûDefault‚Äú mit 0.5 ‚Äì die Scores werden fusioniert.

Das Master-Schema kann bei bestimmten Drifts oder Marker-Clustern das aktive Schema umschalten (z.‚ÄØB. von Smalltalk auf Konfliktanalyse).

Technik:

Format: JSON, im Ordner /schemata/

Pflichtfelder:

id

active_schemata[] (Liste von aktiven SCH_ Profilen)

priority{} (Map: SCH_ ‚Üí Gewicht [0‚Äì1])

fusion (Score-Kombilogik, z.‚ÄØB. ‚Äûmultiply‚Äú, ‚Äûsum‚Äú, ‚Äûmax‚Äú)

Optional: Kontextsensitive Aktivierungslogik (z.‚ÄØB. per Fenster, Trigger, Driftzone)

Zusammenspiel:
Das Master-Schema l√§dt und steuert die Profile aus /schemata/, sorgt f√ºr Score-Fusion, und loggt Schemawechsel (wichtig f√ºr Verlaufsauswertung und adaptive Profiler).

Detect-Spec (DETECT_)
Funktion:
Detect-Specs (Prefix: DETECT_) definieren die Logik, nach der aus Rohdaten (Text, Metrikreihen, Sentimentserien) primitive Marker ausgel√∂st werden. Sie sind der regelbasierte Einstiegspunkt f√ºr die Marker-Engine.

Beispiel:

DETECT_ABSAGE_REGEX.json feuert bei bestimmten Absage-Phrasen einen S_ABSAGE_INDIR-Marker.

DETECT_EMO_VOLATILE.json pr√ºft, ob die Varianz der Emotionen in einem 10-Nachrichten-Fenster einen Schwellenwert √ºberschreitet und feuert dann S_EMO_VOLATILE_WINDOW.

Technik:

Format: JSON, im Ordner /detect/

Pflichtfelder:

id (Regel-Name)

rule (Objekt mit Typ, Parametern, z.‚ÄØB. Regex, Stddev, Frequency)

fire_marker (Marker-ID, die bei Regel-Treffer gefeuert wird)

Typen:

regex: Regex-Matching

stddev: Schwankungen in numerischen Serien

frequency: Schwellenwert f√ºr Wiederholung

trend_delta, embedding_distance, cross_speaker_pattern: f√ºr komplexe Muster

Zusammenspiel:
Detect-Specs werden von einem zentralen Runner verarbeitet, triggern Marker-IDs, die an die nachgelagerte Analyse (Schema, Cluster, Meta) weitergereicht werden.

Grabber / Plugins (GR_META_, GR_)
Funktion:
Grabber sind semantische Zusatzmodule, die komplexe Muster erkennen, die √ºber klassische Regeln hinausgehen. Sie sind als Plugins entworfen und erweitern das System um KI- und Embedding-Logik, etwa f√ºr indirekte Ablehnung, Anomalien oder Feingef√ºhl f√ºr Tonalit√§tsdrift.

Beispiel:

GR_SEM_ABSAGE.js nutzt Embeddings, um semantische N√§he zu typischen Absagen zu erkennen und schl√§gt S_ABSAGE_INDIR als Marker vor.

GR_KIMI_SUGGEST.py sendet Kommunikationscluster an ein LLM, das Vorschl√§ge f√ºr Meta-Tags oder weitere Analyse gibt.

Technik:

Meta: JSON im Ordner /grabber_meta/ (dokumentiert Zweck, Beispiele, Link zum Plugin)

Plugin:

.js im Ordner /plugins/ (f√ºr Frontend/Electron/Chrome)

.py im Ordner /plugins/ (f√ºr Backend/CLI)

Pflichtfelder:

id

description

Exportierte Funktion: run(text, utils, meta) (liefert Marker-Vorschl√§ge & Score)

Zusammenspiel:
Grabber laufen nach Detect, feuern keine Marker automatisch, sondern schlagen sie vor (GUI-Integration, Audit-Log). Sie k√∂nnen als KI-Advisor, Embedding-Semantiker, oder auch als Experimentierfeld f√ºr neue Methoden genutzt werden.

Score-Profile (SCR_)
Funktion:
Ein Score-Profile (Prefix: SCR_) definiert, wie Marker √ºber einen Zeitraum aggregiert und zu quantitativen Werten (Scores) verrechnet werden. Diese Scores k√∂nnen z.‚ÄØB. als Zeitreihen, f√ºr Alerts oder als Trendanalysen genutzt werden ‚Äì etwa um zu erkennen, wie stark Flirt, R√ºckzug, Manipulation oder Bindung sich √ºber den Chatverlauf ver√§ndern.

Beispiel:

SCR_FLIRT_ESCALATION.json berechnet, wie oft und mit welcher Intensit√§t Flirt-Marker in 30 Nachrichten auftreten.

SCR_SPEAKER_IMPACT_OVER_TIME.json summiert Impact-Scores pro Sprecher in 50er-Fenstern.

Technik:

Format: JSON, im Ordner /scores/

Pflichtfelder:

id (Score-Profil-Name)

target_markers[] (Liste der Marker-IDs, die einflie√üen)

window (z.‚ÄØB. "messages": 30)

aggregation (Methode: sum, mean, max, optional decay)

Erweiterungen:

Score-Skalen, Alarmschwellen, Reporting-Optionen

Zusammenspiel:
Score-Profile werden periodisch oder nach jedem neuen Marker-Event berechnet. Sie liefern numerische Auswertungen f√ºr Reporting, Alerts, Heatmaps und f√ºr tiefergehende Driftanalysen.

Calculate / Baseline (CAL_)
Funktion:
Calculate-Module (Prefix: CAL_) dienen zur Erzeugung von Referenzwerten und Baselines. Sie analysieren Chatdaten (meist zu Beginn) und berechnen f√ºr jeden Sprecher typische Kennzahlen: Durchschnittsl√§nge von Nachrichten, Emoji-Frequenz, Prim√§rmarker, Valence-Mittelwerte usw. Die bekannteste und wichtigste Instanz ist die Baseline-Berechnung.

Beispiel:

CAL_BASELINE_PROFILE.py wertet die ersten 20 Nachrichten pro Sprecher aus und speichert Durchschnittswerte als Startpunkt f√ºr sp√§tere Driftanalysen.

CAL_MARKER_FREQUENCY_TRACKER.json berechnet Markerh√§ufigkeiten √ºber Zeit.

Technik:

Format: Python-Script oder JSON, im Ordner /calculate/

Pflichtfelder (Script):

Funktion produce_baseline() oder main(), die aus Nachrichten ein JSON-Baseline-Profil erzeugt

Pflichtfelder (JSON):

id, method (z.‚ÄØB. ‚Äûmean+stdev √ºber 20 Nachrichten‚Äú), Option f√ºr Fenstergr√∂√üe

Zusammenspiel:
Calculate-Module werden einmalig zu Beginn oder regelm√§√üig aufgerufen, um Referenzwerte zu setzen. Diese dienen Profiler- und Score-Modulen als dynamischer Vergleich (‚ÄûHat sich der Stil ver√§ndert?‚Äú).

Profiler (PROF_)
Funktion:
Profiler (Prefix: PROF_) sind Module zur dynamischen Trend- und Driftanalyse. Sie √ºberwachen, ob und wie sich Kommunikationsmuster im Verlauf ver√§ndern ‚Äì z.‚ÄØB. ob sich die Emotionalit√§t, Marker-Dichte, Emoji-Rate oder Stilistik signifikant von der Baseline absetzt.
‚ÄûDrift‚Äú hei√üt: Ein Wert bewegt sich au√üerhalb des normalen Erwartungsbereichs.

Beispiel:

PROF_EWMA_DRIFT.py nutzt exponentiell gewichtetes Mittel (EWMA), um schleichende Ver√§nderungen (‚Äûslow drift‚Äú) von Impact-Scores zu erkennen.

PROF_MARKER_VOLATILITY.py trackt die Varianz von Marker-Treffern √ºber Zeit.

Technik:

Format: Python-Script oder JSON, im Ordner /profiler/

Pflichtfelder:

Klasse/Funktion mit update(score) und idealerweise drifted(threshold)

Speicherung von Trends, Events, Alerts als JSON-Ausgabe oder DB-Update

Zusammenspiel:
Profiler konsumieren Werte aus Calculate- und Score-Modulen, erkennen Abweichungen von Baselines und k√∂nnen Alerts, Heatmaps oder Analyse-Triggers feuern.
Sie sind der ‚ÄûW√§chter‚Äú f√ºr Ver√§nderungen im Kommunikationsstil ‚Äì und Grundlage f√ºr systemische Drift-Analysen oder Reporting.

Zusammenspiel dieser Klassen
Calculate (CAL_) generiert Start-Baselines und Referenzwerte.

Profiler (PROF_) √ºberwachen laufend Ver√§nderungen gegen√ºber der Baseline.

Score-Profile (SCR_) aggregieren Marker-Ereignisse, berechnen Zeitreihen und liefern quantitative Analysen f√ºr Reporting, Alerts oder Entscheidungsregeln.

Typischer Ablauf:

Chat startet ‚Üí CAL_ berechnet Baselines pro Sprecher ‚Üí PROF_ √ºberwacht Drift ‚Üí SCR_ erzeugt fortlaufende Scores ‚Üí Reports/Heatmaps/Alerts basieren auf diesen Analysen.

Cluster Marker Editor ‚Äì Hintergrund, Funktion, Nutzen
Kontext: Warum Cluster Marker bearbeiten?
Cluster Marker sind zentrale Bausteine des Analyse-Systems:
Sie b√ºndeln mehrere Atomic- und Semantic Marker, um komplexe Beziehungsmuster, Kommunikationsdrifts oder Eskalationen zu erkennen, die durch einzelne Marker allein nicht erfassbar w√§ren.
Beispiel: Ein einzelnes ‚ÄûTraurigkeits‚Äú-Wort (A_MARKER) ist wenig aussagekr√§ftig, aber eine Serie von R√ºckzugs-, Ironie- und Distanz-Mustern (als Cluster) signalisiert vielleicht eine Beziehungskrise.

Cluster Marker:

Fassen typische Muster zu sinnvollen Gruppen zusammen (z.‚ÄØB. ‚ÄûBindungsflucht‚Äú, ‚ÄûLatente Eskalation‚Äú, ‚ÄûIronische Entfremdung‚Äú)

Definieren Schwellenwerte: Wie viele Marker, in welchem Zeitfenster, m√ºssen gemeinsam auftreten?

K√∂nnen individuell gewichtet und im Schema angepasst werden

Wozu ein Cluster Editor?
Der Cluster Editor ist ein spezielles UI-Modul, das das Zusammenstellen, Bearbeiten und Testen von Cluster Markern maximal einfach, transparent und kollaborativ macht.

Er unterst√ºtzt dich bei:

Zusammenstellen: Welche Marker geh√∂ren zu einem Cluster? Welche Dynamik will ich messen?

Konfigurieren: Schwellenwerte, Trigger-Logik, Zeitfenster, Gewicht

Validieren: √úberpr√ºfung auf Zyklen, L√ºcken, Dopplungen, zu breite oder zu enge Muster

Testen: Sofortige Vorschau, wie der Cluster auf Beispieldaten reagiert

Versionieren: Sicheres Verwalten, Vergleichen und Dokumentieren aller Cluster-Regeln

Typische Funktionen & Features
1. Marker-Auswahl & Gruppierung
Such- und Filterfunktion f√ºr alle Atomic und Semantic Marker

Drag & Drop, Checkboxen oder Multiselect: Marker k√∂nnen einfach zu einem Cluster hinzugef√ºgt werden

Anzeige der Metadaten (Name, Beschreibung, Gewicht, Beispiele) jedes Markers

2. Cluster-Konfiguration
Eingabefeld f√ºr Cluster-ID und Beschreibung

Felder f√ºr:

composed_of: (Liste der enthaltenen Marker-IDs)

trigger_threshold: (z.‚ÄØB. ‚Äûmind. 2 Marker aktiv innerhalb von 10 Nachrichten‚Äú)

window: (Gr√∂√üe des Analysefensters, z.‚ÄØB. 10, 20 oder flexibel)

impact_score: (optional, f√ºr Priorisierung im Schema)

Optionale Parameter: ‚Äûstrict order‚Äú (Marker m√ºssen in bestimmter Reihenfolge vorkommen?), ‚Äûallow repeats‚Äú, ‚Äûexclusive cluster‚Äú etc.

3. Validierung & Test
Button f√ºr Live-Validierung (z.‚ÄØB. YAML/JSON-Struktur, Referenzen stimmen, keine Marker fehlen)

Button f√ºr Cluster-Test: Simuliert Cluster auf Beispieldialog oder Testdaten

Visuelle R√ºckmeldung: Wie oft wird der Cluster getroffen, bei welchen Beispielen?

4. Vorschau & Export
YAML- oder JSON-Vorschau des fertigen Cluster-Markers

Sofort-Export in das Projektverzeichnis (‚Äûmarkers/cluster/C_NEUER_CLUSTER.yaml‚Äú)

Versionsvergleich: ‚ÄûWas hat sich seit dem letzten Commit ge√§ndert?‚Äú

5. Dokumentation & UX
Hilfe-Panel: Erkl√§rt Sinn und Auswirkungen von Schwellenwerten, Fenstern, etc.

Templates: Vorlagen f√ºr typische Cluster (z.‚ÄØB. ‚ÄûWithdrawal‚Äú, ‚ÄûIronie-Cluster‚Äú)

Kommentarfelder f√ºr Team-Notizen oder Review-Anmerkungen

Beispiel: Cluster Editor in der Praxis
Ziel:
Ein neuer Cluster ‚ÄûAffektiver R√ºckzug‚Äú soll alle Muster b√ºndeln, die f√ºr emotionale Distanzierung sprechen.

Workflow:

Suche nach Markern mit ‚ÄûDistanz‚Äú, ‚ÄûIronie‚Äú, ‚Äûwenig Resonanz‚Äú

W√§hle 4 relevante Marker per Klick aus, ziehe sie in den Cluster-Bereich

Setze Trigger-Threshold: ‚Äûmin. 2 Marker in 10 Nachrichten‚Äú

Setze Fenster: 10

F√ºge Beschreibung und Beispiele hinzu

Dr√ºcke ‚ÄûTesten‚Äú mit einem Chatbeispiel ‚Äì Feedback: ‚ÄûCluster wurde 3x getriggert, z.‚ÄØB. hier: ...‚Äú

Klicke ‚ÄûValidieren & Exportieren‚Äú ‚Äì der YAML-Code liegt im Projekt bereit.

Integration ins System
Im Schema-Builder-GUI:
Eigener Tab ‚ÄûCluster-Editor‚Äú neben ‚ÄûMarker-Import‚Äú und ‚ÄûSchema-Export‚Äú

Backend:
Exportiert YAML nach markers/cluster/, Updates sind f√ºr die Marker Engine sofort verf√ºgbar

CI-Checks:
Cluster werden bei jedem Commit automatisch gepr√ºft (Zyklen, Referenzen, Mindestanzahl von Submarkern, etc.)

Nutzen f√ºr die Praxis
Erh√∂ht die Transparenz komplexer Regeln

Erlaubt Teams, ihr Wissen √ºber Dynamiken direkt in die Engine zu √ºbersetzen ‚Äì ohne YAML zu editieren

Macht die Wartung und Weiterentwicklung von Analyse-Schemata nachhaltiger und effizienter

! Hier kommen f√ºr jede wichtige Klasse (abseits der Marker!)
je ein valider ("good") und ein absichtlich fehlerhafter ("bad") Beispiel-File.
Du kannst diese direkt in deine Testsuite √ºbernehmen.

1Ô∏è‚É£ Score-Profile ‚Äì SCR_
tests/good/SCR_simple_window.json
json
Kopieren
Bearbeiten
{
  "id": "SCR_FRAUD_SCORE",
  "target_markers": ["A_FRAUD_PAYMENT", "S_LOVE_BOMBING"],
  "window": { "messages": 50 },
  "aggregation": { "method": "sum" }
}
tests/bad/SCR_missing_agg.json
json
Kopieren
Bearbeiten
{
  "id": "SCR_NO_AGGREGATION",
  "target_markers": ["A_FRAUD_PAYMENT"],
  "window": { "messages": 30 }
  // FEHLT: "aggregation"
}
2Ô∏è‚É£ Detektor ‚Äì DETECT_
tests/good/DETECT_fraud_payment.json
json
Kopieren
Bearbeiten
{
  "id": "DETECT_FRAUD_PAYMENT",
  "description": "Findet typische Geldforderungen im Text.",
  "rule": {
    "type": "regex",
    "pattern": "(√ºberweise|transfer|send(e)? mir.*geld|money request)",
    "flags": "i"
  },
  "fire_marker": "A_FRAUD_PAYMENT"
}
tests/bad/DETECT_missing_pattern.json
json
Kopieren
Bearbeiten
{
  "id": "DETECT_FRAUD_MISSING_PATTERN",
  "rule": {
    "type": "regex"
    // FEHLT: pattern
  },
  "fire_marker": "A_FRAUD_PAYMENT"
}
3Ô∏è‚É£ Grabber-Plugin ‚Äì GR_
tests/good/GR_simple_plugin.py
python
Kopieren
Bearbeiten
id = "GR_SIMPLE_EXAMPLE"
description = "Testet einen simplen Grabber."
def run(text, utils=None, meta=None):
    if "magicword" in text.lower():
        return {"fire": ["S_MAGIC"], "score": 1}
    return {"fire": [], "score": 0}
tests/bad/GR_no_run_method.py
python
Kopieren
Bearbeiten
id = "GR_MISSING_RUN"
description = "Plugin ohne run()-Methode."
# FEHLT: def run(...)
4Ô∏è‚É£ Schema-Profil ‚Äì SCH_
tests/good/SCH_fraud_profile.json
json
Kopieren
Bearbeiten
{
  "id": "SCH_FRAUD",
  "weights": { "A_": 1.1, "S_": 1.5, "C_": 2, "MM_": 2 },
  "window": { "messages": 100 },
  "decay": 0.01,
  "risk_thresholds": { "green": 0, "yellow": 5, "red": 10 }
}
tests/bad/SCH_missing_weights.json
json
Kopieren
Bearbeiten
{
  "id": "SCH_BAD_PROFILE",
  "window": { "messages": 100 }
  // FEHLT: "weights"
}
5Ô∏è‚É£ Master-Schema ‚Äì MASTER_SCH_
tests/good/MASTER_SCH_example.json
json
Kopieren
Bearbeiten
{
  "id": "MASTER_SCH_CORE",
  "active_schemata": ["SCH_FRAUD", "SCH_BEZIEHUNG"],
  "priority": { "SCH_FRAUD.json": 1.2, "SCH_BEZIEHUNG.json": 1.0 },
  "fusion": "multiply"
}
tests/bad/MASTER_SCH_no_priority.json
json
Kopieren
Bearbeiten
{
  "id": "MASTER_SCH_BAD",
  "active_schemata": ["SCH_FRAUD"],
  "fusion": "sum"
  // FEHLT: "priority"
}
6Ô∏è‚É£ Profiler ‚Äì PROF_
tests/good/PROF_simple.py
python
Kopieren
Bearbeiten
class ProfilerExample:
    def __init__(self): self.mean = None
    def update(self, val): self.mean = val if self.mean is None else 0.5*self.mean+0.5*val
    def drifted(self): return self.mean and self.mean > 0.9
tests/bad/PROF_no_update.py
python
Kopieren
Bearbeiten
class ProfilerBad:
    # FEHLT: update(self, val)
    def drifted(self): return False
7Ô∏è‚É£ Chunk-Analyse ‚Äì CHA_
tests/good/CHA_chunk_fraud.yaml
yaml
Kopieren
Bearbeiten
id: CHA_FRAUD_OVERVIEW
description: "Chunk-Analyse f√ºr Fraud"
detectors_active:
  - DETECT_FRAUD_PAYMENT
  - DETECT_LOVE_BOMBING
high_level_snapshot:
  include_levels: [C_, MM_]
  top_k: 10
drift_axes:
  - speaker_valence
  - payment_requests
outputs:
  show_markers: true
  show_drift: true
  store_json: true
tests/bad/CHA_no_detectors.yaml
yaml
Kopieren
Bearbeiten
id: CHA_MISSING_DETECTORS
description: "Fehler: keine aktiven Detektoren"
# FEHLT: detectors_active
high_level_snapshot:
  include_levels: [C_]
  top_k: 5
drift_axes: []
outputs:
  show_markers: true